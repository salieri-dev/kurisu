This project demonstrates a mature and robust architecture with several well-implemented best practices ideal for a modern, scalable application.

1.  **Three-Tier Service Architecture:** The system is cleanly divided into three distinct services, each with a clear responsibility:
    *   **`backend`**: A FastAPI application that serves as the brain. It handles all business logic, data processing, and interactions with the database.
    *   **`bot`**: A Pyrogram-based Telegram bot that acts as the user interface. It is lightweight, primarily responsible for receiving user commands and forwarding them to the `backend`. It does not contain complex business logic.
    *   **`worker`**: A dedicated asynchronous worker that processes background tasks (like saving messages to the database) from a Redis queue. This decouples message ingestion from processing, making the bot more responsive and the system more resilient.

2.  **Layered Backend Architecture:** The `backend` service strictly follows the **Repository-Service-Endpoint** pattern, which promotes separation of concerns:
    *   **Endpoint (`endpoint.py`):** The API layer (controller). It's responsible for handling HTTP requests, validating input (via Pydantic), and calling the appropriate service method. It knows nothing about the database.
    *   **Service (`service.py`):** The business logic layer. It coordinates operations, processes data, and enforces rules. It calls repository methods to interact with data but doesn't know the specifics of the database implementation.
    *   **Repository (`repository.py`):** The data access layer. Its sole responsibility is to communicate with the database (e.g., MongoDB). It contains all the database queries and handles data persistence.

3.  **Extensible Plugin System:** Both the `backend` and `bot` are built on a plugin-based architecture.
    *   The backend features an elegant auto-discovery mechanism (`backend/plugins/__init__.py`) that automatically finds and registers FastAPI routers from plugin directories. This makes adding new API features as simple as creating a new folder with the required files.
    *   The bot uses Pyrogram's native plugin system to load command handlers from the `plugins/` directory, keeping the main application file clean and focused.

4.  **Structured and Contextual Logging:** The project uses `structlog` for all logging.
    *   A shared `kurisu_core` library provides a consistent logging configuration for all services.
    *   The backend's `structured_logging_middleware` automatically injects contextual information (like `user_id`, `chat_id`, `request_path`) into every log record for a given request.
    *   **Crucially, it implements Correlation IDs (`X-Correlation-ID`)**, which are generated by the bot and passed to the backend. This allows for tracing a single user action across all services and their logs, which is invaluable for debugging.

5.  **Robust Configuration and Dependency Management:**
    *   Configuration is managed via `pydantic-settings`, loading variables from `.env` files. This provides type-safe, validated configuration.
    *   The backend uses FastAPI's dependency injection system (`Depends`) extensively to provide database connections, repositories, and services to endpoints. This improves testability and decouples components.

6.  **Centralized Utilities and Error Handling:**
    *   The `bot` uses a centralized `APIClient` (`bot/utils/api_client.py`) to handle all communication with the backend. This class standardizes header creation (including the Correlation ID), request logic, and error handling.
    *   Custom exception classes (`ServiceError`, `APIError`) are used to provide meaningful error information between layers and services.
    *   The bot uses decorators (`@handle_api_errors`, `@rate_limit`, `@nsfw_guard`) to apply cross-cutting concerns like error reporting, rate limiting, and permissions, keeping the core command logic clean.

7.  **Containerization and Orchestration:** The entire application is containerized using Docker, with a `docker-compose.yml` file to manage the services, database, and cache. This ensures a consistent and reproducible development and deployment environment.

---

## Contributing Guidelines (`CONTRIBUTING.md`)

Welcome to the Kurisu project! We're excited that you want to contribute. To ensure a smooth and consistent development process, please follow these guidelines.

### Core Principles

*   **Separation of Concerns:** Each service (`backend`, `bot`, `worker`) has a distinct role. Stick to it. The bot handles UI, the backend handles logic, and the worker handles background tasks.
*   **Layered Logic:** All backend features must follow the **Endpoint -> Service -> Repository** pattern.
*   **Extensibility First:** New features should be implemented as self-contained plugins whenever possible.
*   **Log Everything, Intelligently:** We use `structlog` for structured, contextual logging. Every log message should contribute to the observability of the system.

### Project Structure

*   `kurisu/`
    *   `backend/`: The FastAPI application. All business logic, database interaction, and heavy lifting happens here.
    *   `bot/`: The Pyrogram Telegram bot. It's the "face" of the application, responsible for user interaction.
    *   `worker/`: An asynchronous worker that processes messages from the Redis queue and saves them to MongoDB.
    *   `kurisu_core/`: A shared Python package used by all services, primarily for a unified logging configuration.
    *   `docker-compose.yml`: Defines all services for local development.
    *   `.env`: Holds all secrets and configuration (you'll need to create this from `.env.example`).

### The Development Workflow: Adding a New Command

Let's say you want to add a `/fact` command that retrieves a random fact from the database.

**Step 1: Create the Backend Plugin**

1.  **Create the Plugin Directory:**
    Create a new folder: `backend/plugins/fun/fact/`.

2.  **Define Models (`models.py`):**
    Create `backend/plugins/fun/fact/models.py` to define the API response structure using Pydantic.
    ```python
    from pydantic import BaseModel

    class FactResponse(BaseModel):
        text: str
        author: str
    ```

3.  **Create the Repository (`repository.py`):**
    Create `backend/plugins/fun/fact/repository.py`. This class will handle fetching data from the `facts` collection in MongoDB.
    ```python
    from motor.motor_asyncio import AsyncIOMotorCollection
    # ... import custom exceptions

    class FactRepository:
        def __init__(self, collection: AsyncIOMotorCollection):
            self._collection = collection

        async def get_random_fact(self) -> dict:
            # Your MongoDB aggregation query to get a random document
            pipeline = [{"$sample": {"size": 1}}]
            cursor = self._collection.aggregate(pipeline)
            fact = await cursor.to_list(length=1)
            if not fact:
                raise NotFoundError("No facts found in the database.")
            return fact[0]
    ```

4.  **Create the Service (`service.py`):**
    Create `backend/plugins/fun/fact/service.py`. This class contains the business logic.
    ```python
    from .repository import FactRepository
    from .models import FactResponse

    class FactService:
        def __init__(self, repository: FactRepository):
            self.repository = repository

        async def get_a_random_fact(self) -> FactResponse:
            fact_data = await self.repository.get_random_fact()
            return FactResponse(text=fact_data["text"], author=fact_data["author"])
    ```

5.  **Create the Endpoint (`endpoint.py`):**
    Create `backend/plugins/fun/fact/endpoint.py` to expose the service via an HTTP endpoint. The auto-discovery system will automatically pick this up.
    ```python
    from fastapi import APIRouter, Depends
    from .service import FactService, get_fact_service # get_fact_service is a dependency provider
    from .models import FactResponse

    router = APIRouter()

    @router.get("", response_model=FactResponse)
    async def get_random_fact(service: FactService = Depends(get_fact_service)):
        return await service.get_a_random_fact()
    ```

**Step 2: Create the Bot Command Handler**

1.  **Create the Plugin File:**
    Create a new file: `bot/plugins/fact.py`.

2.  **Write the Handler:**
    This handler will call the new backend endpoint and reply to the user.
    ```python
    import structlog
    from pyrogram import Client, filters
    from pyrogram.types import Message
    from utils.api_client import backend_client
    from utils.decorators import handle_api_errors, rate_limit

    log = structlog.get_logger(__name__)

    @Client.on_message(filters.command("fact"), group=1)
    @rate_limit(seconds=5) # Apply a 5-second rate limit
    @handle_api_errors   # Automatically handle API errors and show a user-friendly message
    async def handle_fact_command(client: Client, message: Message):
        log.info("Fetching a random fact")
        result = await backend_client.get("/fun/fact", message=message)
        await message.reply(f"**Факт:** {result['text']}\n\n*— {result['author']}*")
    ```

### Key Concepts to Adhere To

#### Structured Logging & Correlation IDs

This is the most important concept for observability.

*   **Always use `structlog`:** Get your logger with `log = structlog.get_logger(__name__)`. Never use `print()`.
*   **The Flow:** The `bot`'s `BackendClient` generates a `X-Correlation-ID` header for every request. The `backend`'s `structured_logging_middleware` reads this ID and binds it to the logging context for the entire request lifecycle.
*   **Your Role:** You don't need to manage the ID yourself. Just use the logger, and the context will be added automatically. This allows us to trace a user's `/fact` command from the bot, through the backend service, to the database repository, and back.

#### Available Utilities

Don't reinvent the wheel. Use the provided utilities.

*   **`bot/utils/api_client.py`**: Use the global `backend_client` instance for *all* communication with the backend. It handles authentication, headers, and error parsing.
*   **`bot/utils/decorators.py`**:
    *   `@handle_api_errors`: Wrap any command handler that talks to the backend with this. It provides a consistent error message to the user.
    *   `@rate_limit`: Use this to prevent spamming of commands.
    *   `@nsfw_guard`: For commands that may produce NSFW content, this decorator will automatically check the chat's configuration.
    *   `@bind_context`: Use this for more complex handlers to ensure logging context is available.
*   **`backend/utils/exceptions.py`**: In your services and repositories, raise specific exceptions like `NotFoundError` or `BadRequestError`. The global exception handler in `backend/main.py` will turn these into proper HTTP responses.
*   **`backend/utils/dependencies.py`**: Use FastAPI's `Depends` with the provided functions to get database collections and other resources.

### Code Style & Linting

We use **Ruff** for formatting and linting. The configuration is in `.pre-commit-config.yaml`.

1.  Install pre-commit: `pip install pre-commit`
2.  Set up the Git hook: `pre-commit install`
3.  Now, before you commit, your code will be automatically formatted and checked for errors. Please ensure your commits pass these checks.

### Submitting Changes

1.  Fork the repository.
2.  Create a new branch for your feature (`git checkout -b feature/add-fact-command`).
3.  Make your changes, following the guidelines above.
4.  Commit your changes with a descriptive message.
5.  Push your branch to your fork (`git push origin feature/add-fact-command`).
6.  Open a Pull Request against the `main` branch of the original repository.

Thank you for contributing
